{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: \n",
    "    * Regress against 2015 data (or end of summary year, whenever possible)\n",
    "    \n",
    "Option 2:\n",
    "    * Regress against change over same summary period\n",
    "    * Theory - this is observing structural shifts in economy (Material Flow and extractive activities) \n",
    "    ... or changes in political economy (World Bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions\n",
    "* Country columns share the same georeferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "import requests as req\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.INFO)\n",
    "import random\n",
    "\n",
    "from functools import reduce\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cartoframes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CARTO_USER = 'wri-rw'#os.environ.get('CARTO_USER')\n",
    "CARTO_KEY = ''#os.environ.get('CARTO_KEY')\n",
    "\n",
    "cc = cartoframes.CartoContext(base_url='https://{}.carto.com/'.format(CARTO_USER),\n",
    "                              api_key=CARTO_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = #os.environ.get('aws_access_key_id')\n",
    "aws_secret_access_key = #os.environ.get('aws_secret_access_key')\n",
    "\n",
    "s3_bucket = \"wri-public-data\"\n",
    "s3_folder = \"resourcewatch/wide_to_long/\"\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "# Functions for reading and uploading data to/from S3\n",
    "def read_from_S3(bucket, key, index_col=0):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    df = pd.read_csv(io.BytesIO(obj['Body'].read()), index_col=[index_col], encoding=\"utf8\")\n",
    "    return(df)\n",
    "\n",
    "def write_to_S3(df, bucket, key):\n",
    "    csv_buffer = io.StringIO()\n",
    "    # Need to set encoding in Python2... default of 'ascii' fails\n",
    "    df.to_csv(csv_buffer, encoding='utf-8')\n",
    "    s3_resource.Object(bucket, key).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to run regressions with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATAX = pd.read_csv('/Users/nathansuberi/Documents/GitHub/nsuberi.github.io/Compass Degrees for Summary Period.csv')\n",
    "DATAY = cc.read('com_009_flowmfa')\n",
    "PROD_NAMES = cc.read('com_009_mfa13').set_index('v1')\n",
    "FLOW_NAMES = cc.read('com_009_flow').set_index('flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datax.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_unique(df, col):\n",
    "    return df[col].unique()\n",
    "\n",
    "def run_linear_regressions(datax, xyear, xval_col, xcountry_col, xname,\n",
    "                           datay, ystartyear, yendyear,\n",
    "                           yprod_col, yflow_col,\n",
    "                           yyear_col, yval_col, \n",
    "                           ycountry_col,\n",
    "                           test_size):\n",
    "    ''' \n",
    "    Inputs: Data and needed column names\n",
    "    Outputs: square matrix of regression coefficients for each indicator\n",
    "    '''\n",
    "    data = datay.copy()\n",
    "    \n",
    "    # Only look at comparisons of traded products\n",
    "    data = data[pd.notnull(data[yprod_col])]\n",
    "        \n",
    "    # Create lists of countries, products, and flows to loop over\n",
    "    all_countries, all_products, all_flows = [extract_unique(data, col) for col in [ycountry_col, yprod_col, yflow_col]]\n",
    "    logging.debug('all_countries: {}'.format(all_countries))\n",
    "    logging.debug('all_products: {}'.format(all_products))\n",
    "    logging.debug('all_flows: {}'.format(all_flows))\n",
    "    \n",
    "    # Result will be an upper right triangular square matrix in 4 dimensions\n",
    "    results = {}    \n",
    "    for prod_y in all_products:\n",
    "        for flow_y in all_flows:\n",
    "            # Extract data\n",
    "            # TO DO: allow for year ranges\n",
    "            data_x = datax.copy()\n",
    "                \n",
    "            logging.debug('flow y: {}'.format(flow_y))\n",
    "            logging.debug('prod y: {}'.format(prod_y))\n",
    "\n",
    "            msg = \"regressing GHG-GDP Divergence Index against {flow_y} of {prod_y}\"\n",
    "            msg = msg.format(flow_y = flow_y,\n",
    "                       prod_y = prod_y)\n",
    "\n",
    "            logging.info(msg)\n",
    "\n",
    "            data_y_start = data.loc[(data[yyear_col] == ystartyear) & (data[yprod_col]==prod_y) & (data[yflow_col]==flow_y)]\n",
    "            data_y_start = data_y_start.set_index(ycountry_col)\n",
    "            # Avoid division by 0\n",
    "            data_y_start = data_y_start.loc[data_y_start[yval_col] > 0]\n",
    "            \n",
    "            data_y_end = data.loc[(data[yyear_col] == yendyear) & (data[yprod_col]==prod_y) & (data[yflow_col]==flow_y)]\n",
    "            data_y_end = data_y_end.set_index(ycountry_col)\n",
    "            \n",
    "            logging.debug('Start {}'.format(data_y_start.head()))\n",
    "            logging.debug('End {}'.format(data_y_end.head()))\n",
    "            \n",
    "            data_y = data_y_end[yval_col].div(data_y_start[yval_col])\n",
    "            data_y = data_y[pd.notnull(data_y)]\n",
    "            logging.debug('Change percent: {}'.format(data_y.head()))\n",
    "            \n",
    "            # Throw away all but intersection of countries\n",
    "            logging.debug('data_x countries: {}'.format(set(data_x[xcountry_col])))\n",
    "            logging.debug('data_y countries: {}'.format(set(data_y.index)))\n",
    "            keep_countries = set(data_x[xcountry_col]) & set(data_y.index)\n",
    "            skipped_countries = [country for country in all_countries if country not in keep_countries]\n",
    "\n",
    "            data_x = data_x.set_index(xcountry_col).loc[keep_countries, xval_col]\n",
    "            data_y = data_y.loc[keep_countries]\n",
    "\n",
    "            # Reshape for regression\n",
    "            data_x = data_x.values.reshape(-1, 1)\n",
    "            data_y = data_y.values.reshape(-1, 1)\n",
    "            \n",
    "            if (len(data_x)>test_size) & (len(data_y)>test_size):\n",
    "                pass\n",
    "            else:\n",
    "                results[(flow_y, prod_y)] = {\n",
    "                    'r_squared': None,\n",
    "                    'skipped_countries': skipped_countries\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # Split for training / test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, \n",
    "                                                                test_size=test_size, random_state=42)\n",
    "\n",
    "            # Run regression\n",
    "            lm = linear_model.LinearRegression() \n",
    "            lm.fit(X_train, y_train)\n",
    "\n",
    "            # Extract coefficient of determination (r^2)\n",
    "            r_squared = lm.score(X_test, y_test)\n",
    "            #y_pred = lm.predict(X_test)\n",
    "            #r_squared2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "            logging.info('rsquared: {}'.format(r_squared)) #, r_squared2))\n",
    "            logging.info('num skipped countries: {}'.format(len(skipped_countries)))\n",
    "            logging.info('num training countries: {}'.format(len(X_train)))\n",
    "            logging.info('num testing countries: {}'.format(len(X_test)))\n",
    "\n",
    "            # Store results\n",
    "            results[(flow_y, prod_y)] = {\n",
    "                'r_squared': r_squared,\n",
    "                'skipped_countries': skipped_countries\n",
    "            }\n",
    "            \n",
    "\n",
    "    return results\n",
    "\n",
    "def pretty_print_results(data_tuple, df_prod_names, df_flow_names):\n",
    "    \n",
    "    flow_y, prod_y = data_tuple[0]\n",
    "    \n",
    "    \n",
    "    ## ALERT TO MATERIAL FLOWS!!!! DATA DOESNT USE SHORTHAND FOR EXPORT AND IMPORT\n",
    "    prod_y_name = df_prod_names.loc[prod_y, 'v2']\n",
    "    try:\n",
    "        flow_y_name = df_flow_names.loc[flow_y, 'flow.name']\n",
    "    except:\n",
    "        flow_y_name = flow_y\n",
    "    \n",
    "    new_tuple = (('compass_of_divergence', flow_y_name, prod_y_name), data_tuple[1])\n",
    "    \n",
    "    return new_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'datax': DATAX,\n",
    "    'xname':'compass of divergence',\n",
    "    'xyear': None,\n",
    "    'xval_col': 'prod_degree',\n",
    "    'xcountry_col': 'country',\n",
    "    'datay': DATAY,\n",
    "    'ystartyear': 2000,\n",
    "    'yendyear': 2015,\n",
    "    'yprod_col': 'mfa13',\n",
    "    'yflow_col': 'flow',\n",
    "    'yyear_col': 'time',\n",
    "    'yval_col': 'value',\n",
    "    'ycountry_col': 'isoalpha3',\n",
    "    'test_size':30\n",
    "}\n",
    "\n",
    "regression_results = run_linear_regressions(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logging.info('Number of regressions attempted: {}'.format(len(regression_results)))\n",
    "#logging.info('Results: {}'.format(regression_results))\n",
    "\n",
    "def pick_not_null(d):\n",
    "    new_d = dict()\n",
    "    for key, vals in d.items():\n",
    "        if vals['r_squared']:\n",
    "            new_d[key] = vals\n",
    "    return new_d\n",
    "\n",
    "notnull_results = pick_not_null(regression_results)\n",
    "\n",
    "\n",
    "sorted_results = sorted(notnull_results.items(), \n",
    "                        key=lambda res: res[1]['r_squared'], \n",
    "                        reverse=True)\n",
    "             \n",
    "# Only keep non-perfect correlations, \n",
    "# and ones for which no more than 10 countries are skipped\n",
    "filterd_sorted_results = [res for res in sorted_results if \n",
    "                  (res[1]['r_squared'] < 1) and \n",
    "                  (len(res[1]['skipped_countries']) < 40) ]\n",
    "\n",
    "readable_results = list(map(lambda tup: pretty_print_results(tup, PROD_NAMES, FLOW_NAMES), \n",
    "                            filterd_sorted_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readable_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
