{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cartoframes\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "import requests as req\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from dateutil import parser\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "logging.basicConfig(stream=sys.stderr, level=logging.INFO)\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* id_columns and data columns are provided as ; separated lists w/ no spaces, i.e. rw_country_name;rw_country_code;commodity_name;category\n",
    "* All data columns have a prefix, followed by a 4-digit year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CARTO_USER = 'wri-rw'#os.environ.get('CARTO_USER')\n",
    "CARTO_KEY = ''#os.environ.get('CARTO_KEY')\n",
    "\n",
    "cc = cartoframes.CartoContext(base_url='https://{}.carto.com/'.format(CARTO_USER),\n",
    "                              api_key=CARTO_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticating to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = ''#os.environ.get('aws_access_key_id')\n",
    "aws_secret_access_key = ''#os.environ.get('aws_secret_access_key')\n",
    "\n",
    "s3_bucket = \"wri-public-data\"\n",
    "s3_folder = \"resourcewatch/wide_to_long/\"\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "# Functions for reading and uploading data to/from S3\n",
    "def read_from_S3(bucket, key, index_col=0):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    df = pd.read_csv(io.BytesIO(obj['Body'].read()), index_col=[index_col], encoding=\"utf8\")\n",
    "    return(df)\n",
    "\n",
    "def write_to_S3(df, bucket, key):\n",
    "    csv_buffer = io.StringIO()\n",
    "    # Need to set encoding in Python2... default of 'ascii' fails\n",
    "    df.to_csv(csv_buffer, encoding='utf-8')\n",
    "    s3_resource.Object(bucket, key).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from RW API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e28cfa2fa604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Request all datasets, and extract the data from the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m### Convert the json object returned by the API into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/simplejson/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, **kw)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mparse_constant\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobject_pairs_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             and not use_decimal and not kw):\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/simplejson/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_PY3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/simplejson/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mord0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0xef\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'\\xef\\xbb\\xbf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 1)"
     ]
    }
   ],
   "source": [
    "# Base URL for getting dataset metadata from RW API\n",
    "url = \"https://api.resourcewatch.org/v1/dataset?sort=slug,-provider,userId&status=saved&includes=metadata,vocabulary,widget,layer\"\n",
    "\n",
    "# page[size] tells the API the maximum number of results to send back\n",
    "# There are currently between 200 and 300 datasets on the RW API\n",
    "payload = { \"application\":\"rw\", \"page[size]\": 1000}\n",
    "\n",
    "# Request all datasets, and extract the data from the response\n",
    "res = req.get(url, params=payload)\n",
    "data = res.json()[\"data\"]\n",
    "\n",
    "### Convert the json object returned by the API into a pandas DataFrame\n",
    "# Another option: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html\n",
    "datasets_on_api = {}\n",
    "for ix, dset in enumerate(data):\n",
    "    atts = dset[\"attributes\"]\n",
    "    metadata = atts[\"metadata\"]\n",
    "    layers = atts[\"layer\"]\n",
    "    widgets = atts[\"widget\"]\n",
    "    tags = atts[\"vocabulary\"]\n",
    "    datasets_on_api[dset[\"id\"]] = {\n",
    "        \"name\":atts[\"name\"],\n",
    "        \"table_name\":atts[\"tableName\"],\n",
    "        \"provider\":atts[\"provider\"],\n",
    "        \"date_updated\":atts[\"updatedAt\"],\n",
    "        \"num_metadata\":len(metadata),\n",
    "        \"metadata\": metadata,\n",
    "        \"num_layers\":len(layers),\n",
    "        \"layers\": layers,\n",
    "        \"num_widgets\":len(widgets),\n",
    "        \"widgets\": widgets,\n",
    "        \"num_tags\":len(tags),\n",
    "        \"tags\":tags\n",
    "    }\n",
    "\n",
    "# Create the DataFrame, name the index, and sort by date_updated\n",
    "# More recently updated datasets at the top\n",
    "current_datasets_on_api = pd.DataFrame.from_dict(datasets_on_api, orient='index')\n",
    "current_datasets_on_api.index.rename(\"Dataset\", inplace=True)\n",
    "current_datasets_on_api.sort_values(by=[\"date_updated\"], inplace=True, ascending = False)\n",
    "\n",
    "# Select all Carto datasets on the API:\n",
    "provider = \"cartodb\"\n",
    "carto_ids = (current_datasets_on_api[\"provider\"]==provider)\n",
    "carto_data = current_datasets_on_api.loc[carto_ids]\n",
    "\n",
    "logging.info(\"Number of Carto datasets: \" + str(carto_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load longforming config & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data sets info from config file\n",
    "# longform_config = pd.read_csv('/Users/nathansuberi/Desktop/RW_Data/longforming_tasks/longform_these.csv')\n",
    "# longform_config = longform_config.set_index('wri_id')\n",
    "# longform_config\n",
    "\n",
    "#### Download Google Spreadsheets ####\n",
    "# Longform Config\n",
    "!curl \"https://docs.google.com/spreadsheets/d/1OjLN9yDbAyuh51uWezOIei5hWkTMU3yTJys_S7miUpU/export?format=tsv\" > longform_config.tsv\n",
    "longform_config = pd.read_csv(open(\"longform_config.tsv\", \"r\"), sep=\"\\t\", index_col=[0])\n",
    "os.remove(\"longform_config.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "longform_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data sets into memory for processing\n",
    "def load_data(obj, elem):\n",
    "    print(elem)\n",
    "    wri_id = elem[0].strip()\n",
    "    rw_id = elem[1].strip()\n",
    "    try:\n",
    "        table_name = carto_data.loc[rw_id]['table_name']\n",
    "        obj[wri_id] = {\n",
    "            'name':table_name,\n",
    "            'wide':cc.read(table_name)\n",
    "        }\n",
    "        logging.info('Table name: {}'.format(obj[wri_id]['name']))\n",
    "        logging.info('Table shape: {}'.format(obj[wri_id]['wide'].shape))\n",
    "    except:\n",
    "        obj[wri_id] = 'Unavailable'\n",
    "        print('Unavailable')\n",
    "    return obj\n",
    "\n",
    "data_tables = reduce(load_data, zip(longform_config.index,longform_config['rw_id']), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use known prefixes to reformat tables\n",
    "def pick_value_col(col, pfx):\n",
    "    if (pfx in col) and (len(col) == len(pfx) + 4):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def prepare_date(date, pfx, parse_date):\n",
    "    if parse_date:\n",
    "        dt = parser.parse(date[date.index(pfx) + len(pfx):])\n",
    "        dt = dt.replace(month=1)\n",
    "        return dt.replace(day=1)\n",
    "    else:\n",
    "        return date[date.index(pfx) + len(pfx):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Longforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for wri_id, info in data_tables.items():\n",
    "    name = info['name']\n",
    "    wide = info['wide']\n",
    "    #logging.debug(wide.head())\n",
    "    \n",
    "    prefixes = longform_config.loc[wri_id, 'prefixes'].split(';')\n",
    "    id_cols = longform_config.loc[wri_id, 'id_cols'].split(';')\n",
    "    parse_date = True if longform_config.loc[wri_id, 'parse_date'] == True else False\n",
    "    logging.debug(\"Parsing date? {}\".format(parse_date))\n",
    "    \n",
    "    logging.info('initial shape: ' + str(wide.shape))\n",
    "    \n",
    "    df = pd.DataFrame(columns = id_cols + ['variable'])\n",
    "    \n",
    "    for pfx in prefixes:\n",
    "        logging.info('working on pfx ' + pfx)\n",
    "        \n",
    "        value_cols = [col for col in wide.columns if pick_value_col(col, pfx)]\n",
    "        logging.info('columns pulled: ' + str(value_cols))\n",
    "\n",
    "        _df = pd.melt(wide, id_vars=id_cols, value_vars=value_cols)\n",
    "        logging.info(_df['variable'])\n",
    "        d = _df['variable']\n",
    "        _df['variable'] = [prepare_date(date, pfx, parse_date) for date in _df['variable']]\n",
    "\n",
    "        col_names = [pfx+'_data' if col=='value' else col for col in _df.columns]\n",
    "        _df.columns = col_names\n",
    "\n",
    "        df = df.merge(_df, on=id_cols  + ['variable'], how='outer')\n",
    "        logging.debug('intermediate df shape: ' + str(df.shape))\n",
    "\n",
    "    logging.info('final shape of ' + wri_id + ': ' + str(df.shape))\n",
    "\n",
    "    new_cols = ['datetime' if col=='variable' else col for col in df.columns]\n",
    "    df.columns = new_cols\n",
    "    logging.info('final columns: ' + str(df.columns))\n",
    "    \n",
    "    data_tables[wri_id]['long'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_tables['ene.029']['long']['yr__data'] = list(map(cast_as_num, data_tables['ene.029']['long']['yr__data'] ))\n",
    "#data_tables['cit.020'].keys()\n",
    "data_tables.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ds, info in data_tables.items():\n",
    "    name = info['name']\n",
    "    \n",
    "    wide = info['wide']\n",
    "    #print(wide.head())\n",
    "    long = info['long']\n",
    "    print(long.head())\n",
    "    \n",
    "    \n",
    "    write_to_S3(wide,s3_bucket,s3_folder+name+'_wide.csv')\n",
    "    print('saved ' + name + ' wide data to s3')\n",
    "    write_to_S3(long,s3_bucket,s3_folder+name+'.csv')\n",
    "    print('saved ' + name + ' long data to s3')\n",
    "    \n",
    "    cc.write(long, name, overwrite=True)\n",
    "    cc.write(wide, name+'_wide', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
